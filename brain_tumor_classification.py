# -*- coding: utf-8 -*-
"""brain-tumor-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AhosGI3ZlOlPV1iNlB_QAOl_eM2BGT5D
"""

from google.colab import drive
drive.mount('/content/drive')

# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

import os
import tqdm
import cv2

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications import EfficientNetB3    # Too much RAM
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D

# Source directories

source_dir='/content/drive/MyDrive/Colab Notebooks/Data/Brain-Tumor-Classification-DataSet-master'

train_dir='/content/drive/MyDrive/Colab Notebooks/Data/Brain-Tumor-Classification-DataSet-master/Training'
test_dir='/content/drive/MyDrive/Colab Notebooks/Data/Brain-Tumor-Classification-DataSet-master/Testing'

# Our output classes

classes = sorted(os.listdir(train_dir))
    
num_classes = len(classes)

class_map = {
    'no_tumor': 0,
    'glioma_tumor': 1,
    'meningioma_tumor': 2,
    'pituitary_tumor': 3
}

print(classes)

# First, let's visualize the kind of image data we have in our dataset

length, width = 225, 225

example_images = ['/content/drive/MyDrive/Colab Notebooks/Data/Brain-Tumor-Classification-DataSet-master/Training/glioma_tumor/gg (1).jpg',
                 '/content/drive/MyDrive/Colab Notebooks/Data/Brain-Tumor-Classification-DataSet-master/Training/meningioma_tumor/m (10).jpg',
                 '/content/drive/MyDrive/Colab Notebooks/Data/Brain-Tumor-Classification-DataSet-master/Training/no_tumor/7.jpg',
                 '/content/drive/MyDrive/Colab Notebooks/Data/Brain-Tumor-Classification-DataSet-master/Training/pituitary_tumor/p (1).jpg']

fig = plt.figure(figsize=(8, 8))
columns = 4

for i in range(4):
    img = mpimg.imread(example_images[i])
    img = cv2.resize(img, (width, length))
    fig.add_subplot(1, columns, i+1)
    plt.imshow(img)
    plt.gcf().set_size_inches(18, 18)
    plt.axis(False)
    plt.title(classes[i])
    
plt.show()

# Creating arrays for training

images = []
labels = []

for label in classes:
    fPath = os.path.join('/content/drive/MyDrive/Colab Notebooks/Data/Brain-Tumor-Classification-DataSet-master/Training', label)
    for item in os.listdir(fPath):
        img = cv2.imread(os.path.join(fPath, item))
        img = cv2.resize(img,(length, width))
        img = img.astype('float')
        images.append(img)
        labels.append(class_map[label])

x_train = np.array(images)
y_train = np.array(labels)

# Creating arrays for testing

test_images = []
test_labels = []

for label in classes:
    fPath = os.path.join('/content/drive/MyDrive/Colab Notebooks/Data/Brain-Tumor-Classification-DataSet-master/Testing', label)
    for item in os.listdir(fPath):
        img = cv2.imread(os.path.join(fPath, item))
        img = cv2.resize(img,(length, width)) # All items (train and test) have the same pixel density
        img = img.astype('float')
        test_images.append(img)
        test_labels.append(class_map[label])
        
x_test = np.array(test_images)
y_test = np.array(test_labels)

print(x_train.shape)
print(y_train.shape)

# Defining our CNN

model = tf.keras.models.Sequential([

            tf.keras.layers.Conv2D(64, kernel_size = [3,3], padding = 'same', activation = 'relu', input_shape = x_train.shape[1:]),
            tf.keras.layers.MaxPool2D(pool_size = [3,3]),
            tf.keras.layers.Conv2D(128, kernel_size = [3,3], padding = 'same', activation = 'relu'),
            tf.keras.layers.MaxPooling2D(3,3),
            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
            tf.keras.layers.MaxPooling2D(2,2), 
            tf.keras.layers.Conv2D(32, (3,3), activation='relu'), 
            tf.keras.layers.MaxPooling2D(2,2),
            tf.keras.layers.Dense(1024, activation = 'relu'),
            tf.keras.layers.Dense(512, activation = 'relu'),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(256, activation='relu'), 
            tf.keras.layers.Dense(64, activation='relu'), 
            tf.keras.layers.Dense(4, activation='softmax')  
            
])

print(model.summary())

model.compile(optimizer = optim, loss = loss, metrics = metrics)

model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, verbose = 2)

model.evaluate(x_test, y_test, batch_size = batch_size, verbose = 2)

# Our hyperparameters

lr = 0.0001
batch_size = 90
epochs = 8

loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)
optim = tf.keras.optimizers.Adam(learning_rate = lr)
metrics = ['accuracy']

effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(length, width,3))

model_eff = effnet.output
model_eff = tf.keras.layers.GlobalAveragePooling2D()(model_eff)
model_eff = tf.keras.layers.Dropout(rate=0.5)(model_eff)
model_eff = tf.keras.layers.Dense(4,activation='softmax')(model_eff)
model_eff = tf.keras.models.Model(inputs=effnet.input, outputs = model_eff)

print(model_eff.summary())

model_eff.compile(optimizer = optim, loss = loss, metrics = metrics)

model_eff.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, verbose = 2)



